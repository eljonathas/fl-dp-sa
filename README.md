---
tags: [DP, SecAgg, vision, fds]
dataset: [MNIST]
framework: [torch, torchvision]
---

# Flower Example on MNIST with Differential Privacy and Secure Aggregation

This example demonstrates a federated learning setup using the Flower, incorporating central differential privacy (DP) with client-side fixed clipping and secure aggregation (SA). It is intended for a small number of rounds for demonstration purposes.

This example is similar to the [quickstart-pytorch example](https://github.com/adap/flower/tree/main/examples/quickstart-pytorch) and extends it by integrating central differential privacy and secure aggregation. For more details on differential privacy and secure aggregation in Flower, please refer to the documentation [here](https://flower.ai/docs/framework/how-to-use-differential-privacy.html) and [here](https://flower.ai/docs/framework/contributor-ref-secure-aggregation-protocols.html).

## Set up the project

### Clone the project

Start by cloning the example project:

```shell
git clone --depth=1 https://github.com/adap/flower.git && mv flower/examples/fl-dp-sa . && rm -rf flower && cd fl-dp-sa
```

This will create a new directory called `fl-dp-sa` containing the following files:

```shell
fl-dp-sa
‚îú‚îÄ‚îÄ fl_dp_sa
‚îÇ   ‚îú‚îÄ‚îÄ client_app.py   # Defines your ClientApp
‚îÇ   ‚îú‚îÄ‚îÄ server_app.py   # Defines your ServerApp
‚îÇ   ‚îî‚îÄ‚îÄ task.py         # Defines your model, training, and data loading
‚îú‚îÄ‚îÄ pyproject.toml      # Project metadata like dependencies and configs
‚îî‚îÄ‚îÄ README.md
```

### Install dependencies and project

Install the dependencies defined in `pyproject.toml` as well as the `fl_dp_sa` package.

```shell
# From a new python environment, run:
pip install -e .
```

## Run the project

You can run your Flower project in both _simulation_ and _deployment_ mode without making changes to the code. If you are starting with Flower, we recommend you using the _simulation_ mode as it requires fewer components to be launched manually. By default, `flwr run` will make use of the Simulation Engine.

### Run with the Simulation Engine

> \[!NOTE\]
> Check the [Simulation Engine documentation](https://flower.ai/docs/framework/how-to-run-simulations.html) to learn more about Flower simulations and how to optimize them.

```bash
flwr run .
```

You can also override some of the settings for your `ClientApp` and `ServerApp` defined in `pyproject.toml`. For example:

```bash
flwr run . --run-config "noise-multiplier=0.1 clipping-norm=5"
```

### Run with the Deployment Engine

Follow this [how-to guide](https://flower.ai/docs/framework/how-to-run-flower-with-deployment-engine.html) to run the same app in this example but with Flower's Deployment Engine. After that, you might be intersted in setting up [secure TLS-enabled communications](https://flower.ai/docs/framework/how-to-enable-tls-connections.html) and [SuperNode authentication](https://flower.ai/docs/framework/how-to-authenticate-supernodes.html) in your federation.

If you are already familiar with how the Deployment Engine works, you may want to learn how to run it using Docker. Check out the [Flower with Docker](https://flower.ai/docs/framework/docker/index.html) documentation.

# Simula√ß√£o de Aprendizado Federado: FedAvg vs Power of Choice

Este projeto implementa uma simula√ß√£o comparativa entre o algoritmo FedAvg tradicional e a estrat√©gia Power of Choice para sele√ß√£o de clientes em aprendizado federado, utilizando o dataset Fashion-MNIST com distribui√ß√£o Non-IID.

## üìã Caracter√≠sticas da Simula√ß√£o

- **Dataset**: Fashion-MNIST com distribui√ß√£o Non-IID (usando distribui√ß√£o Dirichlet)
- **Modelo**: Rede Neural Convolucional (CNN) otimizada para Fashion-MNIST
- **Clientes**: 50 clientes com dados heterog√™neos
- **Estrat√©gias Comparadas**:
  - **FedAvg**: Sele√ß√£o aleat√≥ria tradicional de clientes
  - **Power of Choice**: Sele√ß√£o baseada em performance hist√≥rica dos clientes
- **M√©trica Principal**: Acur√°cia global no conjunto de teste
- **Visualiza√ß√£o**: Gr√°ficos comparativos gerados automaticamente

## üöÄ Instala√ß√£o e Configura√ß√£o

### 1. Clonar o Reposit√≥rio

```bash
git clone <repository-url>
cd fl-dp-sa
```

### 2. Criar Ambiente Virtual

```bash
python -m venv .venv
source .venv/bin/activate  # Linux/Mac
# ou
.venv\Scripts\activate     # Windows
```

### 3. Atualizar pip e Instalar Depend√™ncias

```bash
pip install --upgrade pip
pip install -e .
```

### 4. Verificar Instala√ß√£o

```bash
python test_setup.py
```

## üéØ Executando a Simula√ß√£o

### Simula√ß√£o Completa (Recomendado)

Execute o script principal que compara ambas as estrat√©gias:

```bash
python simulation.py
```

Este comando ir√°:

1. Executar simula√ß√£o com FedAvg (20 rodadas)
2. Executar simula√ß√£o com Power of Choice (20 rodadas)
3. Gerar gr√°ficos comparativos
4. Exibir resumo dos resultados

### Teste R√°pido

Para verificar se tudo est√° funcionando:

```bash
python test_setup.py
```

## üìä Resultados e Visualiza√ß√µes

A simula√ß√£o gera automaticamente:

### Gr√°ficos Comparativos

- **Evolu√ß√£o da Acur√°cia Global**: Compara√ß√£o da acur√°cia ao longo das rodadas
- **Evolu√ß√£o da Loss Global**: Compara√ß√£o da loss ao longo das rodadas
- **Acur√°cia M√©dia dos Clientes**: Performance m√©dia dos clientes participantes
- **Compara√ß√£o Final**: Acur√°cia final de ambas as estrat√©gias

### Arquivos Gerados

- `results/comparison_fedavg_vs_powerofchoice.png`: Gr√°fico em alta resolu√ß√£o
- `results/comparison_fedavg_vs_powerofchoice.pdf`: Vers√£o em PDF para relat√≥rios

### M√©tricas Coletadas

- Acur√°cia global por rodada
- Loss global por rodada
- Acur√°cia m√©dia dos clientes participantes
- Tempo de execu√ß√£o de cada simula√ß√£o
- Taxa de converg√™ncia

## ‚öôÔ∏è Configura√ß√µes Principais

### Par√¢metros do Dataset

```python
num_clients = 50        # N√∫mero total de clientes
alpha = 0.5            # Concentra√ß√£o Dirichlet (menor = mais Non-IID)
```

### Par√¢metros de Treinamento

```python
num_rounds = 20        # Rodadas de treinamento federado
clients_per_round = 10 # Clientes por rodada (20% de 50)
local_epochs = 1       # √âpocas de treinamento local
batch_size = 32        # Tamanho do batch
learning_rate = 0.001  # Taxa de aprendizado
```

### Par√¢metros Power of Choice

```python
d = 3                  # N√∫mero de candidatos considerados por slot
```

## üèóÔ∏è Estrutura do Projeto

```
fl-dp-sa/
‚îú‚îÄ‚îÄ fl_dp_sa/
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py         # Inicializa√ß√£o do pacote
‚îÇ   ‚îú‚îÄ‚îÄ dataset.py          # Gerenciamento do FMNIST Non-IID
‚îÇ   ‚îú‚îÄ‚îÄ model.py            # Modelo CNN e fun√ß√µes de treinamento
‚îÇ   ‚îú‚îÄ‚îÄ strategies.py       # Estrat√©gias FedAvg e Power of Choice
‚îÇ   ‚îú‚îÄ‚îÄ client_app.py       # Aplica√ß√£o do cliente
‚îÇ   ‚îî‚îÄ‚îÄ server_app.py       # Aplica√ß√£o do servidor
‚îú‚îÄ‚îÄ simulation.py           # Script principal de simula√ß√£o
‚îú‚îÄ‚îÄ test_setup.py          # Testes de configura√ß√£o
‚îú‚îÄ‚îÄ pyproject.toml         # Configura√ß√£o do projeto
‚îî‚îÄ‚îÄ README.md              # Este arquivo
```

## üìà Resultados Esperados

### Power of Choice vs FedAvg

- **Converg√™ncia**: Power of Choice tende a convergir mais rapidamente
- **Acur√°cia Final**: Melhoria esperada de 2-5% na acur√°cia final
- **Estabilidade**: Menor vari√¢ncia entre rodadas
- **Efici√™ncia**: Melhor utiliza√ß√£o de clientes com boa performance

### Fatores de Performance

- **Heterogeneidade dos Dados**: Maior benef√≠cio em cen√°rios mais Non-IID
- **N√∫mero de Clientes**: Benef√≠cio aumenta com mais clientes dispon√≠veis
- **Par√¢metro d**: Valores entre 2-5 geralmente oferecem melhor trade-off

## üîß Otimiza√ß√µes Realizadas

### C√≥digo Limpo e Eficiente

- ‚úÖ Removidos arquivos redundantes (`quick_test_simulation.py`, `simple_simulation.py`, `task.py`)
- ‚úÖ Eliminados imports n√£o utilizados
- ‚úÖ Simplificadas classes abstratas desnecess√°rias
- ‚úÖ Otimizadas depend√™ncias no `pyproject.toml`
- ‚úÖ C√≥digo modular e bem estruturado

### Depend√™ncias M√≠nimas

```toml
dependencies = [
    "flwr[simulation]>=1.18.0",
    "torch==2.6.0",
    "torchvision==0.21.0",
    "matplotlib>=3.5.0",
    "numpy>=1.21.0",
]
```

## üß™ Testes

O projeto inclui testes abrangentes:

```bash
python test_setup.py
```

Verifica:

- ‚úÖ Cria√ß√£o e distribui√ß√£o do dataset Non-IID
- ‚úÖ Inicializa√ß√£o e forward pass do modelo
- ‚úÖ Processo de treinamento
- ‚úÖ Compatibilidade entre componentes

## üìù Notas T√©cnicas

### Modelo CNN

- **Arquitetura**: 3 camadas convolucionais + 3 fully connected
- **Par√¢metros**: 422,026 par√¢metros trein√°veis
- **Regulariza√ß√£o**: Dropout (0.25 e 0.5)
- **Otimizador**: Adam com lr=0.001

### Distribui√ß√£o Non-IID

- **M√©todo**: Distribui√ß√£o Dirichlet com Œ±=0.5
- **Heterogeneidade**: Cada cliente tem distribui√ß√£o diferente de classes
- **Balanceamento**: Evita clientes sem dados

### Power of Choice

- **Algoritmo**: Para cada slot, considera d=3 candidatos e escolhe o melhor
- **M√©trica**: Score baseado na acur√°cia hist√≥rica (√∫ltimas 5 rodadas)
- **Adapta√ß√£o**: Score neutro para clientes novos

## ü§ù Contribui√ß√µes

Para contribuir com o projeto:

1. Fa√ßa fork do reposit√≥rio
2. Crie uma branch para sua feature
3. Execute os testes: `python test_setup.py`
4. Submeta um pull request

## üìÑ Licen√ßa

Apache-2.0

---

**Nota**: Esta implementa√ß√£o foi otimizada para fins educacionais e de pesquisa. Para uso em produ√ß√£o, considere otimiza√ß√µes adicionais de performance e seguran√ßa.
