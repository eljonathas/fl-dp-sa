#!/usr/bin/env python3
"""
Script de teste rÃ¡pido para verificar se a implementaÃ§Ã£o estÃ¡ funcionando
"""

import torch
import numpy as np
from fl_dp_sa.dataset import FMNISTNonIID
from fl_dp_sa.model import FMNISTNet, evaluate_model

def test_dataset():
    """Testa o dataset FMNIST Non-IID"""
    print("ğŸ§ª Testando dataset FMNIST Non-IID...")
    
    # Criar dataset com poucos clientes para teste rÃ¡pido
    dataset = FMNISTNonIID(num_clients=5, alpha=0.5)
    
    # Verificar estatÃ­sticas
    stats = dataset.get_client_stats()
    print(f"   âœ… Dataset criado com {stats['num_clients']} clientes")
    print(f"   âœ… Amostras por cliente: {stats['samples_per_client']}")
    
    # Testar dados de um cliente
    train_loader, val_loader = dataset.get_client_data(0, batch_size=16)
    print(f"   âœ… Cliente 0: {len(train_loader.dataset)} amostras de treino, {len(val_loader.dataset)} de validaÃ§Ã£o")
    
    # Testar dados de teste global
    test_loader = dataset.get_test_data(batch_size=64)
    print(f"   âœ… Conjunto de teste global: {len(test_loader.dataset)} amostras")
    
    return dataset

def test_model(dataset):
    """Testa o modelo CNN"""
    print("\nğŸ§ª Testando modelo CNN...")
    
    # Criar modelo
    model = FMNISTNet()
    print(f"   âœ… Modelo criado com {sum(p.numel() for p in model.parameters())} parÃ¢metros")
    
    # Testar forward pass
    dummy_input = torch.randn(1, 1, 28, 28)
    output = model(dummy_input)
    print(f"   âœ… Forward pass: entrada {dummy_input.shape} -> saÃ­da {output.shape}")
    
    # Testar avaliaÃ§Ã£o com dados reais
    test_loader = dataset.get_test_data(batch_size=64)
    
    # Pegar apenas um batch para teste rÃ¡pido
    data_iter = iter(test_loader)
    data, target = next(data_iter)
    
    model.eval()
    with torch.no_grad():
        output = model(data)
        _, predicted = torch.max(output, 1)
        accuracy = (predicted == target).float().mean().item() * 100
    
    print(f"   âœ… AvaliaÃ§Ã£o em um batch: {accuracy:.2f}% de acurÃ¡cia (modelo nÃ£o treinado)")
    
    return model

def test_training_step(dataset, model):
    """Testa um passo de treinamento"""
    print("\nğŸ§ª Testando passo de treinamento...")
    
    # Obter dados de um cliente
    train_loader, val_loader = dataset.get_client_data(0, batch_size=16)
    
    # Configurar treinamento
    criterion = torch.nn.CrossEntropyLoss()
    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)
    
    # Um passo de treinamento
    model.train()
    data_iter = iter(train_loader)
    data, target = next(data_iter)
    
    optimizer.zero_grad()
    output = model(data)
    loss = criterion(output, target)
    loss.backward()
    optimizer.step()
    
    print(f"   âœ… Passo de treinamento executado, loss: {loss.item():.4f}")
    
    # Verificar se os parÃ¢metros mudaram
    print(f"   âœ… Gradientes calculados e parÃ¢metros atualizados")

def main():
    """FunÃ§Ã£o principal de teste"""
    print("ğŸš€ Iniciando testes de configuraÃ§Ã£o...")
    print("=" * 50)
    
    try:
        # Testar dataset
        dataset = test_dataset()
        
        # Testar modelo
        model = test_model(dataset)
        
        # Testar treinamento
        test_training_step(dataset, model)
        
        print("\n" + "=" * 50)
        print("ğŸ‰ TODOS OS TESTES PASSARAM!")
        print("âœ… O sistema estÃ¡ pronto para executar a simulaÃ§Ã£o completa")
        print("\nPara executar a simulaÃ§Ã£o completa, use:")
        print("   python simulation.py")
        
    except Exception as e:
        print(f"\nâŒ ERRO durante os testes: {e}")
        import traceback
        traceback.print_exc()
        return False
    
    return True

if __name__ == "__main__":
    main() 